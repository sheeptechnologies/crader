{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Crader","text":"<p>Crader turns Git repositories into a code property graph stored in PostgreSQL. It parses code into semantic chunks using Tree-sitter, stores structural relations, and supports keyword and vector search with snapshot isolation.</p>"},{"location":"#what-you-can-do","title":"What you can do","text":"<ul> <li>Index a repository into immutable snapshots</li> <li>Generate embeddings with a staged, deduplicated pipeline</li> <li>Run hybrid search (vector plus keyword) with Reciprocal Rank Fusion</li> <li>Expand results with parent context and outgoing definitions</li> <li>Read files and navigate code blocks from the graph</li> </ul>"},{"location":"#key-notes","title":"Key notes","text":"<ul> <li>Semantic tagging via Tree-sitter queries is currently provided for Python, JavaScript, and TypeScript.</li> <li>The indexer always uses PostgreSQL; SQLite is intended for local experiments and tests. You can implement additional storage providers by extending the <code>GraphStorage</code> interface.</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Getting started: Installation, Quickstart</li> <li>Guides: Architecture, Indexing pipeline, Embedding strategy, Retrieval strategies, Data model</li> <li>API reference: Indexer, Parsing, Embedding, Retrieval, Storage, Models, Reader, Navigator</li> <li>Examples: Advanced usage</li> <li>Contributing: Development setup, Code of conduct</li> <li>Roadmap: Roadmap</li> </ul>"},{"location":"faqs/","title":"FAQ","text":""},{"location":"faqs/#what-is-crader","title":"What is Crader?","text":"<p>Crader indexes Git repositories into a code property graph stored in PostgreSQL. It parses code into chunks using Tree-sitter, stores structural relationships, and supports keyword and vector search.</p>"},{"location":"faqs/#does-crader-do-incremental-indexing","title":"Does Crader do incremental indexing?","text":"<p>Yes. Crader supports file-incremental indexing. When re-indexing a repository, only changed files are processed. Embeddings are deduplicated across snapshots by <code>vector_hash</code>.</p>"},{"location":"faqs/#which-languages-are-supported","title":"Which languages are supported?","text":"<p>Indexing scans files by extension:</p> <ul> <li>.py</li> <li>.js, .jsx</li> <li>.ts, .tsx</li> <li>.java</li> <li>.go</li> <li>.rs</li> <li>.c, .cpp</li> <li>.php</li> <li>.html, .css</li> </ul> <p>Semantic tagging via Tree-sitter queries is currently provided for Python, JavaScript, and TypeScript.</p>"},{"location":"faqs/#why-postgresql-instead-of-a-separate-vector-database","title":"Why PostgreSQL instead of a separate vector database?","text":"<p>Crader stores the graph, full-text index, and vectors in one system. PostgreSQL provides transactional consistency and flexible joins between nodes, edges, and embeddings.</p>"},{"location":"faqs/#index-returns-queued-what-does-it-mean","title":"<code>index()</code> returns \"queued\". What does it mean?","text":"<p>The repository is already locked by another indexing run (a snapshot is still marked <code>indexing</code>). Wait for it to finish or mark the stale snapshot as <code>failed</code> or <code>completed</code> in the database before retrying.</p>"},{"location":"faqs/#search-returns-empty-or-low-quality-results","title":"Search returns empty or low-quality results","text":"<ul> <li>Confirm that a snapshot is active for the repository.</li> <li>Run the embedding pipeline if you are using <code>strategy=\"vector\"</code> or <code>strategy=\"hybrid\"</code>.</li> <li>Remove restrictive filters like <code>path_prefix</code> or <code>language</code>.</li> <li>Use <code>strategy=\"keyword\"</code> to validate FTS results independently of embeddings.</li> </ul>"},{"location":"faqs/#can-i-use-local-embeddings","title":"Can I use local embeddings?","text":"<p>Yes. Use <code>FastEmbedProvider</code> for local embeddings or implement your own <code>EmbeddingProvider</code>.</p>"},{"location":"roadmap/","title":"Roadmap","text":"<p>This page describes the near-term direction for Crader.</p>"},{"location":"roadmap/#current-status","title":"Current status","text":"<p>Crader uses Tree-sitter for parsing and chunking, enabling true file-incremental indexing. The indexer only processes changed files when re-indexing a repository.</p>"},{"location":"roadmap/#planned-work","title":"Planned work","text":"<ul> <li>Extend semantic tagging queries to all supported languages.</li> <li>Preserve the current storage model and retrieval APIs.</li> <li>Add support for additional programming languages.</li> <li>Improve chunking strategies for large files.</li> </ul>"},{"location":"contributing/code-of-conduct/","title":"Code of conduct","text":""},{"location":"contributing/code-of-conduct/#pledge","title":"Pledge","text":"<p>We are committed to providing a welcoming, professional, and harassment-free environment for everyone who participates in this project.</p>"},{"location":"contributing/code-of-conduct/#expected-behavior","title":"Expected behavior","text":"<ul> <li>Be respectful and considerate in all interactions</li> <li>Assume good intent and give constructive feedback</li> <li>Focus on improving the project and supporting the community</li> </ul>"},{"location":"contributing/code-of-conduct/#unacceptable-behavior","title":"Unacceptable behavior","text":"<ul> <li>Harassment, discrimination, or personal attacks</li> <li>Sexualized language or imagery</li> <li>Publishing private information without permission</li> <li>Sustained disruptive behavior</li> </ul>"},{"location":"contributing/code-of-conduct/#reporting","title":"Reporting","text":"<p>If you experience or witness unacceptable behavior, contact the project maintainers. Reports will be reviewed and handled as responsibly and confidentially as possible.</p>"},{"location":"contributing/development-setup/","title":"Development setup","text":"<p>This guide describes a minimal local setup for working on Crader.</p>"},{"location":"contributing/development-setup/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+</li> <li>git</li> <li>Optional: PostgreSQL with pgvector (required for e2e tests)</li> </ul>"},{"location":"contributing/development-setup/#setup","title":"Setup","text":"<pre><code>git clone https://github.com/filippodaminato/crader.git\ncd crader\n\npython -m venv .venv\nsource .venv/bin/activate\n\npip install -e \".[dev]\"\n</code></pre>"},{"location":"contributing/development-setup/#tests","title":"Tests","text":"<p>Unit and integration tests are mostly mocked and do not require a database:</p> <pre><code>pytest tests/unit/ tests/integration/\n</code></pre> <p>End-to-end tests require PostgreSQL and a runnable git environment:</p> <pre><code>pytest tests/e2e/\n</code></pre>"},{"location":"contributing/development-setup/#linting-and-type-checks","title":"Linting and type checks","text":"<pre><code>ruff check src tests\nmypy src\n</code></pre>"},{"location":"contributing/development-setup/#local-postgresql-optional","title":"Local PostgreSQL (optional)","text":"<p>A Docker Compose file is available for the debugger stack:</p> <pre><code>docker compose -f tools/debugger/docker-compose.yml up -d\n</code></pre>"},{"location":"examples/advanced_usage/","title":"Advanced usage","text":"<p>This page collects practical patterns that match the current API surface.</p> <p>Assume you already created a PostgreSQL storage instance and resolved <code>repo_id</code> and <code>snapshot_id</code> as needed.</p>"},{"location":"examples/advanced_usage/#index-multiple-branches","title":"Index multiple branches","text":"<p>Each <code>(url, branch)</code> pair is a separate repository record.</p> <pre><code>from crader import CodebaseIndexer\n\nindexer_main = CodebaseIndexer(\n    repo_url=\"git@github.com:org/repo.git\",\n    branch=\"main\",\n    db_url=db_url,\n)\nindexer_main.index()\nindexer_main.close()\n\nindexer_dev = CodebaseIndexer(\n    repo_url=\"git@github.com:org/repo.git\",\n    branch=\"feature/new-search-api\",\n    db_url=db_url,\n)\nindexer_dev.index(force=True)\nindexer_dev.close()\n</code></pre>"},{"location":"examples/advanced_usage/#keyword-only-search","title":"Keyword-only search","text":"<p>Keyword search does not require embeddings, but <code>CodeRetriever</code> still needs a provider instance.</p> <pre><code>from crader import CodeRetriever\nfrom crader.providers.embedding import DummyEmbeddingProvider\n\nretriever = CodeRetriever(storage, DummyEmbeddingProvider())\nresults = retriever.retrieve(\n    query=\"AuthMiddleware\",\n    repo_id=repo_id,\n    strategy=\"keyword\",\n)\n</code></pre>"},{"location":"examples/advanced_usage/#use-filters-to-reduce-noise","title":"Use filters to reduce noise","text":"<pre><code>results = retriever.retrieve(\n    query=\"router\",\n    repo_id=repo_id,\n    strategy=\"hybrid\",\n    filters={\n        \"language\": [\"python\"],\n        \"exclude_category\": [\"test\"],\n        \"path_prefix\": [\"src/\"]\n    },\n)\n</code></pre>"},{"location":"examples/advanced_usage/#read-files-and-navigate-chunks","title":"Read files and navigate chunks","text":"<pre><code>from crader import CodeReader, CodeNavigator\n\nreader = CodeReader(storage)\nnav = CodeNavigator(storage)\n\n# List a directory\nentries = reader.list_directory(snapshot_id, \"src\")\n\n# Read a file range\nfile_data = reader.read_file(snapshot_id, \"src/app.py\", start_line=1, end_line=80)\n\n# Move to the next chunk in a file\nnext_chunk = nav.read_neighbor_chunk(node_id, direction=\"next\")\n</code></pre>"},{"location":"examples/advanced_usage/#control-the-repo-storage-location","title":"Control the repo storage location","text":"<pre><code>export CRADER_REPO_VOLUME=\"/mnt/crader/repos\"\n</code></pre> <p>This affects the bare mirrors and worktrees created by <code>GitVolumeManager</code>.</p>"},{"location":"examples/advanced_usage/#embed-without-external-apis","title":"Embed without external APIs","text":"<p>Use <code>mock_api=True</code> to generate random vectors for testing:</p> <pre><code>async for update in indexer.embed(provider, batch_size=200, mock_api=True):\n    if update.get(\"status\") == \"completed\":\n        print(update)\n</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide covers the system requirements and setup steps for Crader.</p>"},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+</li> <li>PostgreSQL with the pgvector extension</li> <li>git</li> <li>Optional: OpenAI API key if you use OpenAI embeddings</li> </ul>"},{"location":"getting-started/installation/#install-the-package","title":"Install the package","text":"<pre><code>pip install crader\n</code></pre>"},{"location":"getting-started/installation/#database-setup","title":"Database setup","text":"<p>Set your database URL and run migrations:</p> <pre><code>export CRADER_DB_URL=\"postgresql://user:pass@localhost:5432/codebase\"\ncrader db upgrade\n</code></pre> <p>The migration enables the <code>vector</code> extension and creates all required tables.</p>"},{"location":"getting-started/installation/#environment-variables","title":"Environment variables","text":"<ul> <li><code>CRADER_DB_URL</code>: PostgreSQL connection string (required by CLI and <code>CodebaseIndexer</code>).</li> <li><code>CRADER_REPO_VOLUME</code>: Root directory for cached repos and worktrees (defaults to <code>./sheep_data/repositories</code>).</li> <li><code>CRADER_OPENAI_API_KEY</code> or <code>OPENAI_API_KEY</code>: OpenAI credentials for embeddings.</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quickstart","text":"<p>Index a repository and run a search in a few minutes.</p>"},{"location":"getting-started/quickstart/#1-start-postgresql-if-needed","title":"1. Start PostgreSQL (if needed)","text":"<pre><code>docker run -d --name crader-postgres \\\n  -e POSTGRES_USER=crader \\\n  -e POSTGRES_PASSWORD=crader \\\n  -e POSTGRES_DB=codebase \\\n  -p 5432:5432 \\\n  pgvector/pgvector:pg14\n</code></pre>"},{"location":"getting-started/quickstart/#2-configure-the-database","title":"2. Configure the database","text":"<pre><code>export CRADER_DB_URL=\"postgresql://crader:crader@localhost:5432/codebase\"\ncrader db upgrade\n</code></pre>"},{"location":"getting-started/quickstart/#3-index-a-repository","title":"3. Index a repository","text":"<pre><code>crader index https://github.com/pallets/flask.git --branch main\n</code></pre> <p>This step parses files using Tree-sitter, builds semantic chunks, and stores structural relations. It does not generate embeddings.</p>"},{"location":"getting-started/quickstart/#4-generate-embeddings","title":"4. Generate embeddings","text":"<pre><code>import asyncio\nfrom crader import CodebaseIndexer\nfrom crader.providers.embedding import OpenAIEmbeddingProvider\n\nrepo_url = \"https://github.com/pallets/flask.git\"\nbranch = \"main\"\ndb_url = \"postgresql://crader:crader@localhost:5432/codebase\"\n\nindexer = CodebaseIndexer(repo_url=repo_url, branch=branch, db_url=db_url)\n\nasync def main():\n    provider = OpenAIEmbeddingProvider(model=\"text-embedding-3-small\")\n    async for update in indexer.embed(provider, batch_size=200):\n        if update.get(\"status\") == \"completed\":\n            print(update)\n\nasyncio.run(main())\nindexer.close()\n</code></pre>"},{"location":"getting-started/quickstart/#5-search","title":"5. Search","text":"<pre><code>from crader import CodeRetriever\nfrom crader.providers.embedding import OpenAIEmbeddingProvider\nfrom crader.storage.connector import PooledConnector\nfrom crader.storage.postgres import PostgresGraphStorage\n\ndb_url = \"postgresql://crader:crader@localhost:5432/codebase\"\nrepo_url = \"https://github.com/pallets/flask.git\"\nbranch = \"main\"\n\nconnector = PooledConnector(dsn=db_url)\nstorage = PostgresGraphStorage(connector)\nprovider = OpenAIEmbeddingProvider(model=\"text-embedding-3-small\")\nretriever = CodeRetriever(storage, provider)\n\nrepo_id = storage.ensure_repository(\n    repo_url,\n    branch,\n    repo_url.rstrip(\"/\").split(\"/\")[-1].replace(\".git\", \"\"),\n)\n\nresults = retriever.retrieve(\n    query=\"How does request routing work?\",\n    repo_id=repo_id,\n    limit=3,\n    strategy=\"hybrid\",\n)\n\nfor hit in results:\n    print(hit.file_path, hit.start_line, hit.score)\n</code></pre> <p>Keyword search works without embeddings, but <code>CodeRetriever</code> still requires an embedding provider instance.</p>"},{"location":"guides/architecture/","title":"Architecture","text":"<p>Crader is split into a write path (indexing and embedding) and a read path (search and navigation). The system stores all data in PostgreSQL with snapshot isolation, so readers always query a stable version of the codebase.</p>"},{"location":"guides/architecture/#write-path","title":"Write path","text":"<ul> <li>Repository sync: <code>GitVolumeManager</code> maintains a bare mirror cache and creates ephemeral worktrees for specific commits. Repositories are stored under <code>CRADER_REPO_VOLUME</code> (default: <code>./sheep_data/repositories</code>).</li> <li>Parsing and chunking: <code>TreeSitterRepoParser</code> loads Tree-sitter grammars by extension and splits code into chunks. Chunks include byte ranges, line ranges, and metadata tags. Parent-child edges (<code>child_of</code>) are created during parsing.</li> <li>Storage: <code>PostgresGraphStorage</code> persists repositories, snapshots, files, nodes, contents, edges, and the FTS index.</li> <li>Embeddings (separate step): <code>CodeEmbedder</code> stages node content, deduplicates by hash, then calls an embedding provider. Vectors are stored in <code>node_embeddings</code> for vector search.</li> </ul>"},{"location":"guides/architecture/#read-path","title":"Read path","text":"<ul> <li>Search: <code>CodeRetriever</code> runs vector search and keyword search through <code>SearchExecutor</code>. Results are merged using Reciprocal Rank Fusion.</li> <li>Context expansion: <code>GraphWalker</code> adds parent context and outgoing definitions based on graph edges.</li> <li>Navigation and reading: <code>CodeReader</code> reconstructs files from chunk content and uses the snapshot manifest for fast directory listing. <code>CodeNavigator</code> exposes helpers for neighbors, parent blocks, callers, and callees.</li> </ul>"},{"location":"guides/architecture/#snapshot-model","title":"Snapshot model","text":"<p>Each indexing run creates a snapshot tied to a commit hash. A repository points to a single active snapshot. Queries always target a specific snapshot, either explicitly or by resolving the active one.</p>"},{"location":"guides/data_model/","title":"Data model","text":"<p>Crader stores a code property graph in PostgreSQL. The schema is designed around immutable snapshots and content-addressable storage for chunk text.</p>"},{"location":"guides/data_model/#core-tables","title":"Core tables","text":"<ul> <li>repositories: Unique by <code>(url, branch)</code>. <code>current_snapshot_id</code> points to the active snapshot.</li> <li>snapshots: One row per indexing run and commit hash. <code>status</code> is <code>pending</code>, <code>indexing</code>, <code>completed</code>, or <code>failed</code>. <code>file_manifest</code> stores the directory tree used by <code>CodeReader</code>.</li> <li>files: Files within a snapshot, including <code>language</code>, <code>category</code>, and parsing status.</li> <li>contents: Content-addressable storage for chunk text (<code>chunk_hash</code>), deduplicated across snapshots.</li> <li>nodes: Chunk metadata and byte ranges, referencing <code>files</code> and <code>contents</code>.</li> <li>edges: Directed relationships between nodes (<code>child_of</code>, <code>calls</code>, <code>defines</code>, <code>reads_from</code>, etc.).</li> <li>nodes_fts: Full-text search index built from chunk content and semantic tags.</li> <li>node_embeddings: Vector embeddings for chunks with denormalized fields for fast filtering.</li> <li>staging_embeddings: Unlogged table created during embedding runs for batching and deduplication.</li> </ul>"},{"location":"guides/data_model/#core-entities-python","title":"Core entities (Python)","text":"<p>The <code>crader.models</code> module mirrors the schema for most common objects:</p> <ul> <li><code>Repository</code>, <code>Snapshot</code>, <code>FileRecord</code></li> <li><code>ChunkNode</code>, <code>ChunkContent</code></li> <li><code>CodeRelation</code></li> <li><code>ParsingResult</code>, <code>RetrievedContext</code></li> </ul> <p><code>RetrievedContext</code> is the response type returned by the retriever and includes navigation hints and context expansion.</p>"},{"location":"guides/embedding-strategy/","title":"Embedding strategy","text":"<p>Crader generates embeddings in a separate step using <code>CodebaseIndexer.embed()</code> and <code>CodeEmbedder</code>. The pipeline is staged and deduplicated to reduce API calls.</p>"},{"location":"guides/embedding-strategy/#pipeline-summary","title":"Pipeline summary","text":"<ol> <li>Staging</li> <li>Nodes that are missing embeddings are streamed from the database.</li> <li>Each node is transformed into a prompt and hashed into a <code>vector_hash</code>.</li> <li> <p>Rows are bulk loaded into the <code>staging_embeddings</code> table.</p> </li> <li> <p>Deduplication</p> </li> <li><code>vector_hash</code> is matched against existing embeddings in <code>node_embeddings</code>.</li> <li> <p>If a match exists, the vector is copied into staging.</p> </li> <li> <p>Delta processing</p> </li> <li>Remaining rows are fetched in batches.</li> <li> <p>Workers call the embedding provider and write vectors back to the database.</p> </li> <li> <p>Promotion and cleanup</p> </li> <li>Staged rows with embeddings are promoted into <code>node_embeddings</code>.</li> <li>Staging rows are removed.</li> </ol>"},{"location":"guides/embedding-strategy/#prompt-template","title":"Prompt template","text":"<p><code>CodeEmbedder</code> embeds a structured prompt that combines file metadata and code:</p> <pre><code>[CONTEXT]\nFile: &lt;file_path&gt;\nLanguage: &lt;language&gt;\nCategory: &lt;category&gt;\nRole: &lt;role tags&gt;\nTags: &lt;other semantic tags&gt;\nDefines: &lt;incoming definitions&gt;\n\n[CODE]\n&lt;chunk content&gt;\n</code></pre> <p>The <code>vector_hash</code> is the SHA-256 hash of this full prompt. Moving a file or changing metadata will change the hash.</p>"},{"location":"guides/embedding-strategy/#providers","title":"Providers","text":"<p>Crader ships with these embedding providers:</p> <ul> <li><code>OpenAIEmbeddingProvider</code> (uses <code>CRADER_OPENAI_API_KEY</code> or <code>OPENAI_API_KEY</code>)</li> <li><code>FastEmbedProvider</code> (local embeddings via <code>fastembed</code>)</li> <li><code>DummyEmbeddingProvider</code> (random vectors for tests)</li> </ul> <p>You can implement the <code>EmbeddingProvider</code> interface to integrate another provider.</p>"},{"location":"guides/indexing-pipeline/","title":"Indexing pipeline","text":"<p>This guide describes what happens when you call <code>CodebaseIndexer.index()</code>.</p>"},{"location":"guides/indexing-pipeline/#overview","title":"Overview","text":"<p>The indexer performs a full scan of a repository commit and writes files, chunks, and relations into PostgreSQL. It does not generate embeddings; embeddings are handled by the separate <code>embed()</code> step.</p>"},{"location":"guides/indexing-pipeline/#steps","title":"Steps","text":"<ol> <li>Repository registration</li> <li> <p><code>PostgresGraphStorage.ensure_repository()</code> creates or updates the repository row.</p> </li> <li> <p>Git sync and snapshot creation</p> </li> <li><code>GitVolumeManager</code> updates a bare mirror of the repository.</li> <li><code>create_snapshot()</code> inserts a snapshot with status <code>indexing</code>.</li> <li> <p>If the same commit is already indexed, the existing snapshot is reused.</p> </li> <li> <p>File scan</p> </li> <li>The worktree is scanned with <code>os.walk</code>.</li> <li>Ignored directories: <code>.git</code>, <code>node_modules</code>, <code>__pycache__</code>, <code>.venv</code>, <code>dist</code>, <code>build</code>, <code>target</code>, <code>vendor</code>.</li> <li> <p>Extensions indexed:</p> <ul> <li><code>.py</code>, <code>.js</code>, <code>.jsx</code>, <code>.ts</code>, <code>.tsx</code>, <code>.java</code>, <code>.go</code>, <code>.rs</code>, <code>.c</code>, <code>.cpp</code>, <code>.php</code>, <code>.html</code>, <code>.css</code></li> </ul> </li> <li> <p>Parallel parsing</p> </li> <li>A <code>ProcessPoolExecutor</code> processes file chunks (50 files per task, 5 workers).</li> <li> <p>Each worker uses <code>TreeSitterRepoParser</code> to:</p> <ul> <li>Skip large files (<code>&gt;1 MB</code>), binaries, and minified/generated content.</li> <li>Emit <code>FileRecord</code>, <code>ChunkNode</code>, <code>ChunkContent</code>, and <code>child_of</code> relations.</li> <li>Build FTS documents from chunk metadata and content.</li> </ul> </li> <li> <p>Snapshot activation</p> </li> <li>Indexing stats and a file manifest are generated.</li> <li>The snapshot is marked <code>completed</code> and becomes the active snapshot.</li> </ol>"},{"location":"guides/indexing-pipeline/#notes","title":"Notes","text":"<ul> <li>If a repository is already being indexed, <code>index()</code> returns <code>\"queued\"</code>.</li> <li>Semantic tags from Tree-sitter queries are currently available for Python, JavaScript, and TypeScript.</li> <li>Parsing and indexing always run on the full file set for the target commit.</li> </ul>"},{"location":"guides/retrieval-strategies/","title":"Retrieval strategies","text":"<p><code>CodeRetriever</code> exposes a single entry point, <code>retrieve()</code>, which runs keyword, vector, or hybrid search against a snapshot.</p>"},{"location":"guides/retrieval-strategies/#how-retrieval-works","title":"How retrieval works","text":"<ol> <li>Snapshot resolution</li> <li> <p>If <code>snapshot_id</code> is not provided, the active snapshot for the repository is resolved.</p> </li> <li> <p>Search execution</p> </li> <li>Vector search uses <code>EmbeddingProvider.embed()</code> and <code>PostgresGraphStorage.search_vectors()</code>.</li> <li> <p>Keyword search uses <code>PostgresGraphStorage.search_fts()</code>.</p> </li> <li> <p>Fusion</p> </li> <li> <p>Hybrid search merges results with Reciprocal Rank Fusion (RRF).</p> </li> <li> <p>Context expansion</p> </li> <li><code>GraphWalker</code> adds parent context and outgoing definitions based on graph edges.</li> </ol>"},{"location":"guides/retrieval-strategies/#strategies","title":"Strategies","text":"<ul> <li><code>hybrid</code>: vector plus keyword, merged with RRF.</li> <li><code>vector</code>: vector search only.</li> <li><code>keyword</code>: keyword search only.</li> </ul>"},{"location":"guides/retrieval-strategies/#filters","title":"Filters","text":"<p>The <code>filters</code> argument is pushed into SQL. Supported keys:</p> <ul> <li><code>path_prefix</code></li> <li><code>language</code> / <code>exclude_language</code></li> <li><code>category</code> / <code>exclude_category</code></li> <li><code>role</code> / <code>exclude_role</code></li> </ul>"},{"location":"guides/retrieval-strategies/#example","title":"Example","text":"<pre><code>from crader import CodeRetriever\nfrom crader.providers.embedding import OpenAIEmbeddingProvider\nfrom crader.storage.connector import PooledConnector\nfrom crader.storage.postgres import PostgresGraphStorage\n\ndb_url = \"postgresql://user:pass@localhost:5432/codebase\"\nconnector = PooledConnector(dsn=db_url)\nstorage = PostgresGraphStorage(connector)\nprovider = OpenAIEmbeddingProvider(model=\"text-embedding-3-small\")\nretriever = CodeRetriever(storage, provider)\n\nresults = retriever.retrieve(\n    query=\"authentication middleware\",\n    repo_id=repo_id,\n    limit=5,\n    strategy=\"hybrid\",\n    filters={\"language\": \"python\", \"path_prefix\": \"src/\"},\n)\n</code></pre>"},{"location":"reference/embedding/","title":"Embedding API","text":"<p>The embedding module generates vector embeddings for chunks. It runs asynchronously and uses a staging table to deduplicate work.</p>"},{"location":"reference/embedding/#codeembedder","title":"CodeEmbedder","text":"<pre><code>from crader.embedding.embedder import CodeEmbedder\n\nembedder = CodeEmbedder(storage, provider)\n</code></pre>"},{"location":"reference/embedding/#run_indexing","title":"run_indexing","text":"<pre><code>async for update in embedder.run_indexing(snapshot_id, batch_size=1000, mock_api=False):\n    ...\n</code></pre> <p>Status updates include stages such as <code>init</code>, <code>staging_progress</code>, <code>deduplicating</code>, <code>embedding_progress</code>, and <code>completed</code>.</p>"},{"location":"reference/embedding/#prompt-construction","title":"Prompt construction","text":"<p><code>_compute_prompt_and_hash</code> builds the prompt and hash used for deduplication. The prompt includes:</p> <ul> <li>File path, language, and category</li> <li>Semantic roles and tags (from parser metadata)</li> <li>Incoming definitions (symbols that resolve to this node)</li> <li>Code content</li> </ul> <p>The SHA-256 hash of this prompt is stored as <code>vector_hash</code>.</p>"},{"location":"reference/embedding/#embeddingprovider","title":"EmbeddingProvider","text":"<p>Providers must implement:</p> <ul> <li><code>embed(texts: List[str]) -&gt; List[List[float]]</code></li> <li><code>embed_async(texts: List[str]) -&gt; List[List[float]]</code></li> <li><code>dimension</code> and <code>model_name</code> properties</li> </ul> <p>Built-in providers:</p> <ul> <li><code>OpenAIEmbeddingProvider</code></li> <li><code>FastEmbedProvider</code></li> <li><code>DummyEmbeddingProvider</code></li> </ul>"},{"location":"reference/indexer/","title":"Indexer API","text":"<p><code>CodebaseIndexer</code> orchestrates repository indexing and embedding. It uses PostgreSQL for storage and the Git volume manager for repository worktrees.</p>"},{"location":"reference/indexer/#codebaseindexer","title":"CodebaseIndexer","text":"<pre><code>from crader import CodebaseIndexer\n\nindexer = CodebaseIndexer(\n    repo_url=\"https://github.com/org/repo.git\",\n    branch=\"main\",\n    db_url=\"postgresql://user:pass@localhost:5432/codebase\",\n)\n</code></pre>"},{"location":"reference/indexer/#constructor-arguments","title":"Constructor arguments","text":"<ul> <li><code>repo_url</code> (str): Git remote URL or any URL accepted by <code>git clone</code>.</li> <li><code>branch</code> (str): Branch or tag to index.</li> <li><code>db_url</code> (str, optional): PostgreSQL DSN. Falls back to <code>CRADER_DB_URL</code>.</li> <li><code>worker_telemetry_init</code> (callable, optional): Hook executed in worker processes.</li> </ul>"},{"location":"reference/indexer/#index","title":"index","text":"<pre><code>snapshot_id = indexer.index(force=False, auto_prune=False)\n</code></pre> <p>Runs parsing and relation extraction and stores results in the database.</p> <ul> <li><code>force</code>: if <code>True</code>, create a new snapshot even if the commit is already indexed.</li> <li><code>auto_prune</code>: currently a placeholder. Old snapshots are not removed automatically.</li> </ul> <p>Returns the snapshot ID, or the string <code>\"queued\"</code> when another indexing run is in progress.</p>"},{"location":"reference/indexer/#embed","title":"embed","text":"<pre><code>async for update in indexer.embed(provider, batch_size=1000, mock_api=False, force_snapshot_id=None):\n    ...\n</code></pre> <p>Runs the asynchronous embedding pipeline. This does not run automatically during <code>index()</code>.</p> <ul> <li><code>provider</code>: an <code>EmbeddingProvider</code> implementation.</li> <li><code>batch_size</code>: staging batch size.</li> <li><code>mock_api</code>: generate random vectors for testing.</li> <li><code>force_snapshot_id</code>: embed a specific snapshot instead of the active one.</li> </ul>"},{"location":"reference/indexer/#get_stats","title":"get_stats","text":"<pre><code>stats = indexer.get_stats()\n</code></pre> <p>Returns counters from the database (<code>files</code>, <code>total_nodes</code>, <code>embeddings</code>, <code>snapshots</code>, <code>repos</code>).</p>"},{"location":"reference/indexer/#close","title":"close","text":"<pre><code>indexer.close()\n</code></pre> <p>Closes the database connection pool.</p>"},{"location":"reference/models/","title":"Data models","text":"<p>The <code>crader.models</code> module defines dataclasses used across the pipeline.</p>"},{"location":"reference/models/#core-entities","title":"Core entities","text":"<ul> <li><code>Repository</code>: repository identity and snapshot pointer.</li> <li><code>Snapshot</code>: immutable version tied to a commit hash.</li> <li><code>FileRecord</code>: metadata for a file in a snapshot, including parse status.</li> <li><code>ChunkNode</code>: code chunk with byte range, line range, and metadata.</li> <li><code>ChunkContent</code>: content-addressable storage for chunk text.</li> <li><code>CodeRelation</code>: directed edge between two chunks.</li> <li><code>ParsingResult</code>: aggregate container for parser output.</li> </ul>"},{"location":"reference/models/#retrieval","title":"Retrieval","text":"<ul> <li><code>RetrievedContext</code>: enriched search result returned by <code>CodeRetriever</code>.</li> <li>Includes <code>content</code>, scores, semantic labels, and navigation hints.</li> <li><code>render()</code> returns a Markdown-formatted string.</li> </ul>"},{"location":"reference/navigation/","title":"Navigation API","text":"<p><code>CodeNavigator</code> exposes helpers for traversing the code graph.</p>"},{"location":"reference/navigation/#codenavigator","title":"CodeNavigator","text":"<pre><code>from crader import CodeNavigator\n\nnav = CodeNavigator(storage)\n</code></pre>"},{"location":"reference/navigation/#read_neighbor_chunk","title":"read_neighbor_chunk","text":"<pre><code>next_chunk = nav.read_neighbor_chunk(node_id, direction=\"next\")\nprev_chunk = nav.read_neighbor_chunk(node_id, direction=\"prev\")\n</code></pre> <p>Returns the adjacent chunk in the same file (if any).</p>"},{"location":"reference/navigation/#read_parent_chunk","title":"read_parent_chunk","text":"<pre><code>parent = nav.read_parent_chunk(node_id)\n</code></pre> <p>Returns the enclosing chunk (for example, a class containing a method).</p>"},{"location":"reference/navigation/#analyze_impact","title":"analyze_impact","text":"<pre><code>callers = nav.analyze_impact(node_id, limit=20)\n</code></pre> <p>Returns a list of incoming references (<code>calls</code>, <code>references</code>, <code>imports</code>, <code>instantiates</code>).</p>"},{"location":"reference/navigation/#analyze_dependencies","title":"analyze_dependencies","text":"<pre><code>deps = nav.analyze_dependencies(node_id)\n</code></pre> <p>Returns outgoing calls for the node. If none are available, the method returns <code>None</code>.</p>"},{"location":"reference/navigation/#visualize_pipeline","title":"visualize_pipeline","text":"<pre><code>flow = nav.visualize_pipeline(node_id, max_depth=2)\n</code></pre> <p>Builds a recursive call tree for UI visualization.</p>"},{"location":"reference/parsing/","title":"Parsing API","text":"<p>The parsing layer converts source files into chunked nodes and structural relations using Tree-sitter.</p>"},{"location":"reference/parsing/#treesitterrepoparser","title":"TreeSitterRepoParser","text":"<pre><code>from crader.parsing.parser import TreeSitterRepoParser\n\nparser = TreeSitterRepoParser(repo_path=\"/path/to/repo\")\nparser.snapshot_id = \"&lt;snapshot-id&gt;\"\n</code></pre>"},{"location":"reference/parsing/#stream_semantic_chunks","title":"stream_semantic_chunks","text":"<pre><code>for file_rec, nodes, contents, relations in parser.stream_semantic_chunks(file_list=[\"src/app.py\"]):\n    ...\n</code></pre> <p>Yields:</p> <ul> <li><code>FileRecord</code></li> <li><code>List[ChunkNode]</code></li> <li><code>List[ChunkContent]</code></li> <li><code>List[CodeRelation]</code> (<code>child_of</code> relations within a file)</li> </ul>"},{"location":"reference/parsing/#behavior","title":"Behavior","text":"<ul> <li>Skips files larger than 1 MB, binaries, and minified or generated content.</li> <li>Uses Tree-sitter grammars based on file extension.</li> <li>Semantic tags are extracted from query files in <code>src/crader/parsing/queries/</code>.</li> <li>Queries are provided for Python, JavaScript, and TypeScript.</li> <li>Chunk size limits are byte-based (<code>MAX_CHUNK_SIZE=800</code>, <code>CHUNK_TOLERANCE=400</code>).</li> </ul>"},{"location":"reference/reading/","title":"Reading API","text":"<p><code>CodeReader</code> provides file and directory access on top of snapshot data.</p>"},{"location":"reference/reading/#codereader","title":"CodeReader","text":"<pre><code>from crader import CodeReader\n\nreader = CodeReader(storage)\n</code></pre>"},{"location":"reference/reading/#read_file","title":"read_file","text":"<pre><code>data = reader.read_file(snapshot_id, \"src/app.py\", start_line=1, end_line=80)\n</code></pre> <p>Returns a dictionary with <code>file_path</code>, <code>content</code>, <code>start_line</code>, and <code>end_line</code>. Reads are line-based and reconstructed from stored chunks.</p> <p>If a file exists but has no stored chunks (for example, it was skipped), the content may be an empty string.</p>"},{"location":"reference/reading/#list_directory","title":"list_directory","text":"<pre><code>entries = reader.list_directory(snapshot_id, \"src\")\n</code></pre> <p>Uses the snapshot manifest and returns a list of <code>{name, type, path}</code> entries.</p>"},{"location":"reference/reading/#find_directories","title":"find_directories","text":"<pre><code>paths = reader.find_directories(snapshot_id, \"tests\", limit=10)\n</code></pre> <p>Performs an in-memory search on the manifest and returns matching directory paths.</p>"},{"location":"reference/retrieval/","title":"Retrieval API","text":"<p>The retriever module handles search and context expansion.</p>"},{"location":"reference/retrieval/#coderetriever","title":"CodeRetriever","text":"<pre><code>from crader import CodeRetriever\n\nretriever = CodeRetriever(storage, embedder)\n</code></pre>"},{"location":"reference/retrieval/#retrieve","title":"retrieve","text":"<pre><code>results = retriever.retrieve(\n    query=\"Find auth middleware\",\n    repo_id=repo_id,\n    snapshot_id=None,\n    limit=10,\n    strategy=\"hybrid\",\n    filters=None,\n)\n</code></pre> <p>Arguments:</p> <ul> <li><code>query</code>: natural language or code tokens.</li> <li><code>repo_id</code>: repository ID used to resolve the active snapshot.</li> <li><code>snapshot_id</code>: optional explicit snapshot override.</li> <li><code>limit</code>: max results returned.</li> <li><code>strategy</code>: <code>hybrid</code>, <code>vector</code>, or <code>keyword</code>.</li> <li><code>filters</code>: dictionary of SQL filters (see <code>guides/retrieval-strategies.md</code>).</li> </ul> <p>Returns a list of <code>RetrievedContext</code> objects.</p>"},{"location":"reference/retrieval/#retrievedcontext","title":"RetrievedContext","text":"<p>Key fields:</p> <ul> <li><code>node_id</code>, <code>file_path</code>, <code>start_line</code>, <code>end_line</code></li> <li><code>content</code></li> <li><code>score</code></li> <li><code>semantic_labels</code></li> <li><code>retrieval_method</code></li> <li><code>parent_context</code> (string or None)</li> <li><code>outgoing_definitions</code> (list of symbols)</li> <li><code>nav_hints</code> (IDs for parent/prev/next)</li> </ul>"},{"location":"reference/retrieval/#render","title":"render","text":"<p><code>render()</code> returns a Markdown-formatted string suitable for prompting.</p>"},{"location":"reference/retrieval/#searchexecutor","title":"SearchExecutor","text":"<p><code>SearchExecutor</code> exposes two static helpers used by the retriever:</p> <ul> <li><code>vector_search(storage, embedder, query, limit, snapshot_id, filters, candidates)</code></li> <li><code>keyword_search(storage, query, limit, snapshot_id, filters, candidates)</code></li> </ul>"},{"location":"reference/retrieval/#graphwalker","title":"GraphWalker","text":"<p><code>GraphWalker</code> expands a node result by querying neighbors in the graph. It returns:</p> <ul> <li><code>parent_context</code> describing the containing block</li> <li><code>outgoing_definitions</code> listing called symbols</li> </ul>"},{"location":"reference/storage/","title":"Storage API","text":"<p>Crader uses PostgreSQL as the primary backend. The indexer writes directly through <code>PostgresGraphStorage</code>.</p>"},{"location":"reference/storage/#postgresgraphstorage","title":"PostgresGraphStorage","text":"<pre><code>from crader.storage.connector import PooledConnector\nfrom crader.storage.postgres import PostgresGraphStorage\n\nconnector = PooledConnector(dsn=db_url)\nstorage = PostgresGraphStorage(connector)\n</code></pre>"},{"location":"reference/storage/#repository-and-snapshot-lifecycle","title":"Repository and snapshot lifecycle","text":"<ul> <li><code>ensure_repository(url, branch, name) -&gt; repo_id</code></li> <li><code>create_snapshot(repository_id, commit_hash, force_new=False) -&gt; (snapshot_id, is_new)</code></li> <li>returns <code>(None, False)</code> if another snapshot is currently <code>indexing</code></li> <li><code>activate_snapshot(repository_id, snapshot_id, stats=None, manifest=None)</code></li> <li><code>get_active_snapshot_id(repository_id) -&gt; snapshot_id</code></li> <li><code>fail_snapshot(snapshot_id, error)</code></li> </ul>"},{"location":"reference/storage/#write-operations","title":"Write operations","text":"<ul> <li><code>add_files</code>, <code>add_nodes</code>, <code>add_contents</code></li> <li><code>add_search_index</code> builds the FTS table</li> <li><code>add_edge</code> and <code>add_relations_raw</code> add relations</li> <li>Raw bulk variants exist for high-throughput inserts (<code>add_nodes_raw</code>, etc.)</li> </ul>"},{"location":"reference/storage/#search","title":"Search","text":"<ul> <li><code>search_vectors(query_vector, limit, snapshot_id, filters=None)</code></li> <li><code>search_fts(query, limit, snapshot_id, filters=None)</code></li> </ul> <p>Filter keys:</p> <ul> <li><code>path_prefix</code></li> <li><code>language</code> / <code>exclude_language</code></li> <li><code>category</code> / <code>exclude_category</code></li> <li><code>role</code> / <code>exclude_role</code></li> </ul>"},{"location":"reference/storage/#navigation-helpers","title":"Navigation helpers","text":"<ul> <li><code>get_context_neighbors(node_id)</code></li> <li><code>get_neighbor_chunk(node_id, direction)</code></li> <li><code>get_neighbor_metadata(node_id)</code></li> <li><code>get_incoming_references(node_id)</code></li> <li><code>get_outgoing_calls(node_id)</code></li> </ul>"},{"location":"reference/storage/#embedding-pipeline-helpers","title":"Embedding pipeline helpers","text":"<ul> <li><code>prepare_embedding_staging()</code></li> <li><code>load_staging_data()</code></li> <li><code>backfill_staging_vectors(snapshot_id)</code></li> <li><code>fetch_staging_delta(snapshot_id)</code></li> <li><code>flush_staged_hits(snapshot_id)</code></li> <li><code>save_embeddings_direct(records)</code></li> </ul>"},{"location":"reference/storage/#sqlite-backend","title":"SQLite backend","text":"<p><code>SqliteGraphStorage</code> exists for local experiments and tests. The main indexer uses PostgreSQL and does not switch backends automatically.</p>"}]}